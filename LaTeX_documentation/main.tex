\documentclass[12pt,twoside]{article}
%encoding
\usepackage{fontspec}
%language
\usepackage[english,french]{babel}
%use special characters unicode
\usepackage{xunicode}
\defaultfontfeatures{Ligatures=TeX}
\setmainfont[Numbers=OldStyle]{Junicode}
\usepackage{xspace}
%images and figures
\usepackage{graphicx}
%color tables
\usepackage{colortbl}
\usepackage{xcolor}
%split a table cell in two
\usepackage{diagbox}
\usepackage[style=enc]{biblatex}
 %Imports biblatex package
\addbibresource{biblio/mybibliography.bib} %Import the bibliography file
\usepackage{longtable} %long tables
\usepackage{lscape} %mode paysage
\usepackage{pdflscape}
\usepackage{tabularx}
%images and figures
\usepackage{graphicx}
%new commands
\newcommand{\clearemptydoublepage}{%
	\newpage{\pagestyle{empty}\cleardoublepage}}
	
%add hyperlinks
\usepackage{hyperref}
%metadata
\hypersetup{pdfauthor={Matenia Vlachou}{Noé Léroy},pdftitle={report of project-Boccacius-HN2021},pdfsubject={Detailed report and workflow/process of the project for the course "Bonnes pratiques du développement - Git" first semester 2021, university ENC-PSL, prof.Thibault Clérice},pdfkeywords={Boccacius} {De genealogia deorum gentilium} {incunabula} {latin} {middle French} {OCR} {HTR} {e-Scriptorium} {école nationale des chartes} {Master HN 2021}}

\begin{document}

[Document in process]

\title{Report of HN-project-Boccacius }
\date{January 2022}
\author{\textsc{Léroy }Noé \and {\textsc{Maulu } Marco}\and {\textsc{Vlachou-Efstathiou } Malamatenia }}

\maketitle

\clearpage

\section{Aknowledgements}



\section{Project framework}

The starting point of this project was the assignment given to the contributors for the validation of the course Bonnes pratiques du developpement collaboratif : initiation à Git" (prof. Thibault Clérice), for the first semester - Master Humanités Numériques ENC-PSL 2021-2022. It serves, consequently, primarily as to validate the aforementioned course and as an  initiation to the Digital Humanities toolbox.

At the same time, the project is directly linked to, and constitutes part of the biannual project "Per un'edizione digitale della Genealogia deorum gentilium" di Boccaccio" (dir. F. Duval, M. Maulu). Financed in 2021, this project foresees to put on line in XML format the unpublished translation in Middle French entitled "De la genealogie des dieux". The translation in question was published in Paris by A. Vérard in 1498 and probably realized by Laurent Premierfait, which constitutes one of the two main witnessed treated.\\

The basic idea is to exploit the method of treatment and edition developed during the project "Pour une édition numérique de la Mer des histoires" (dir. F. Duval, M. Maulu). Differences between these two projects can already be underlined, notably the choice of EScriptorium instead of Transkribus, which will be analysed thoroughly below. 
It will also be necessary to verify if more efficient tools than http://stella.atilf.fr/LGeRM/glossaire/ can be used in the automatic text correction process. 
Ultimately, the desired outcomes of the Mdh project are: 
\begin{enumerate}
    \item a decrease in the percentage of error (CER and WER) with a more reliable base text;
    \item  the optimization of a post-HTR processing and correction software
    \item the creation of a new model that can be used for large-scale projects (e.g. a corpus of translations of Latin texts into MF).
\end{enumerate}

The project also includes  the organization of a Summer School in Digital Humanities in Sassari. \\


Although fundamental, a study of the original text in Latin has not been included for budgetary reasons: compared to the Mdh tradition, which translates a medieval work printed in 1475, the tradition of Boccaccio's work is more extensive.The tradition is exclusively printed and the \textit{editio princeps} is therefore of absolute value ( cf. Hortis \footcite{hortis1879} and Ernest \footcite{ernest1919}) . Given the importance of the author in question and the fact that a true critical edition of \textit{Genealogia} has not been published until now, partial surveys of some of the Latin manuscripts and prints that transmit it could help to understand which textual branch provided the model for the translation published by Vérard.

\clearpage

\section{Presentation and description of document sources}

The data set of the present project consists of two documents, both of them \textit{incunabula}, presented here in chronological order.\\
The first one, namely Mazarine \footnote{Abbreviation of the Bibliothèque Mazarine, located in Paris, France.} Inc.59, contitutes the \textit{editio princeps} of the work edited in Venice in 1472\footnote{The document belongs to the public domain.Link to the notice of the library online : https://mazarinum.bibliotheque-mazarine.fr/records/item/1781-genealogia-deorum and to the IIIF manifest:  https://mazarinum.bibliotheque-mazarine.fr/iiif/1781/manifest}. Its format is \textit{in-folio}, numbers 295 folios/leafs, was produced in paper \footnote{for the terminology and the accurate translation from French to English we use the handbook of Denis Muzerelle \textit{Répertoire méthodique
des termes français
relatifs aux manuscrits}, IRHT,CNRS,Paris, available online : http://www.palaeographia.org/vocabulaire/vocab.htm }, measures 322 x 234 x 69 mm and its binding is in case-hardened calf. It was previously owned by Ferdinand I (king of Naples; 1431?-1494) and the
Royal Library of France (15..-1792)\\ 


\clearpage
\section{Tools and Methods}

The two main tools used for the project, other than our personal toil were EScriptorium and GitHub.

\subsection{eScriptorium}
There are plenty OCR (Optical Character Recognition) software : some are proprietary and some are free, and they all have specificities making them more suitable for one project over another.As per the software used for the transcription of Boccacius documents, we used Kraken, through its interface eScriptorium, an OCR system derived from OCRopus, an older OCR system \footnote{Detailed description of the project provided by Professor Peter A. Stokes here : https://www.resilience-ri.eu/blog/resilience-tool-escriptorium/}.

There are two main reasons behind this choice. First of all, it is a well-developed free software with extensive documentation (on an interface \href{https://traces6.paris.inria.fr/}{working interface} and on a GitLab \href{https://gitlab.com/scripta/escriptorium/}{repository}). More specifically, the ENC staff has actively and extensively worked on the project with versions of kraken and eScriptorium and trained models themselves, which means that it was easier fot the team to be trained, to present and resolve issues, be they technical or methodological.

Access to eScriptorium was given from a virtual environment which was fairly easy to navigate and use. It takes on by default the preprocessing steps of binarizing and segmenting the images before performing the transcription, all of this using provided pretrained models, or enabling the user to train customized modeles, as we did for the two documents. The software also offers many options for tailoring the transcription process or the training, depending on the language and layout specificities. 

It is important to note that tools such as eScriptorium, that necessitate a complex preparation of the documents in order to give quality results, may not be worth the effort  applying on one short document, or a number of heterogeneous documents (that are all written with very different scripts or layouts). On the other hand, as it was the case for \textit{Mazarine Inc.59} and \textit{BnF. Rés. J-845} for large and relatively coherent \textit{corpus}, then this software is very useful as it  automatises the process of transcription.

Of course, using artificial intelligence and trained models does not mean that the documents are magically transcribed with impeccable accuracy, which means that a manual supervised - and/or philological- correction of the transcription is necessary. More will be discussed on the process, difficulties and limits for the models trained by the team for this project later.


\subsection{GitHub}

GitHub\href{https://github.com/} is an easily accessible open-source repository, sort like a cloud for code. It hosts source code projects of any kind and keeps track of the changes made. Repositories are public, which means that other GitHub users can review and propose changes to a code via three basic processes: \texttt{fork}, \texttt{push}, \texttt{pull requests}that can be manipulated either from the terminal or from the interface itself. Proposed changes can be merged into the software after the proposals/issues are reviewed and approved. This means that we had a powerful tool to work collaboratively and add progressively to  our work while keeping track of the process. Our personal organisation hosting the Boccacius project is called Boccacius - De genealogia deorum gentilium and its repository can be found here \href{https://github.com/HN-2021-Boccacius/git-project-Boccace}.

A defining feature of GitHub the version control system, accessible, between others, though GitHub Actions. The version control allows developers to establish a workflow,  and potentially fix bugs or improving efficiency without affecting the software itself.+++++

\clearpage
\section{Mazarine Inc. 59}

Passing on to the individual process of preparation, segmentation and transcription of the documents, starting with the \textit{editio princeps}.

\subsection{Segmentation process,norms and limits}

The documents, given that is a well curated print, did not pose insurmountable difficulties with the layout. Some features taken into consideration for the training of the segmentation model were:
\begin{enumerate}
    \item The division of the page into columns, applicable only to the first 20 pages that present the "Table of content". The model was trained to read the columns one by one vertically, instead of each line horizontally.
    \item  The posterior addition of the \textit{foliation} (page numbering) in arabic numerals on the top right of each \textit{recto} of the \textit{bifolio}. The lighter -comparing to the main text- ink  made it difficult for recognizing the foliation at the start. At this point it is important to note that the text was divided into two \textit{regions}, the main text (capital initials included) and the page numbering and while exporting the text only these two labels were chosen.
    \item The initial capitals. It was particularly tricky to train the machine into recognizing the initial letters for two reasons. Firstly, as expected, they do not precede the line that normally follows the same baseline but a previous line (usually wither one or two levels above). Secondly, they are often times omitted, which means that there is a space left. These two factors made it impossible to integrate them into a full line with their complement, and imposed a separate line for the initials that would then be re positioned prior to the corresponding line. 
    An additional problem was the printing of the capitals in a second time over the corresponding minuscule letters that indicate where the capitals should be placed. 
 \end{enumerate}   
 
\begin{figure}[h!]
    \centering
    \includegraphics[width=5cm]{initial_capitals.jpg}
    \caption{Overwritten initals}
    \label{fig:PremFigure}
\end{figure}


This being said, since eScriprotium recognizes characters, and for this case one should eliminate the other, it was proved to be a fastidious task for the training procedure and was eventually corrected by hand in all cases.


\subsection{Transcription process,norms and limits}
A valuable guide was that of Capelli \footcite{cappelli1982elements} in order to verify the abbreviation and ligature system used in the \textit{incunabulum}/print.\\

\begin{landscape}

\pagestyle{empty}

%creating my special characters commands
\newcommand{\rum}{\char"A75D\xspace}
\newcommand{\pro}{\char"A753\xspace}
\newcommand{\per}{\char"A751\xspace}
\newcommand{\eced}{\char"0119\xspace}
\newcommand{\quod}{\char"A759\xspace}
\newcommand{\Quod}{\char"A756\xspace}
\newcommand{\ussup}{\char"1DD2\xspace}
\newcommand{\pre}{\char"A751\xspace}
\newcommand{\macron}{\char"0303\xspace}
\newcommand{\ursup}{\char"1DD1\xspace}
\newcommand{\opena}{\char"1DD3\xspace}
\newcommand{\qu}{\char"A757\xspace}
\newcommand{\isup}{\char"0365\xspace}
\newcommand{\etc}{.2c\opena{}.\xspace}
\newcommand{\sm}{\char"1E9C{}m\xspace}


\begin{table}[!h]
\centering
\begin{tabularx}{\textwidth}{| X | X | X |X|}\hline
\textsc{Abbreviation}     & \texttt{mufi unicode} (if applicable)    & \textsc{special character sign}  & \textsc{examples} \\ \hline\hline
omission of macron & 0303 & \macron{} & e\macron{} a\macron{} i\macron{} m\macron{}etc. \\\hline
ligature of est & - & e\macron{}& \\\hline
ligature of esse & - & ee\macron{} & \\\hline
open a superscript & 1DD3 & \opena{} & q\opena{} \\\hline
-rum        & A75D     & \rum{}   or 4 & re\rum{} \\ \hline
-i superscript &  0365 & \isup{} & \qu{}\isup{}, p\isup{}  \\\hline
-ur superscript & 1DD1 & \ursup{} & t\ursup{} \\\hline
-ae &  0119 & \char"0119 &\\\hline
Abbreviation of -us / 9 superscript & IDD2 & \ussup{} & r\ussup{}\\\hline
suffix pro & A753 & \pro{} & \pro{}ducta \\\hline
suffix per & A751 & \pre{} & \per{}crutat\ursup{} \\\hline
Abbreviation of quod & A759 & \quod{} & \\\hline
Abbreviation of Quod & A759 & \Quod{} & \\\hline
abbreviation of qu (+ macron) & A757 & \qu{} & tran\qu{}litatem  \\\hline
Ligature of quam & A757 + 1DD3 & \qu{}\opena{} & tam\qu{}\opena{}, um\qu{}\opena{} \\\hline
abbreviation of etcaetera & - & \etc{} \footnote{Replacing the tironian textit{et} with 2 because in this case it represents better the representation of the sign. The tironian "and" is never found isolated in the document.} & \\\hline
abbreviation of \textit{secundum} & 1E9C + m & \sm{}& \\\hline
\end{tabularx}

\caption{\textsc{Transcription guidelines. Table of special character signs}}
\label{table:1}
\end{table}

\end{landscape}

With these conventions in hand, that serve as out base and cover, in combination or not, all of the signs witnessed in the document \footnote{At least on the fist 27 pages that were transcribed and corrected for the project. In any new characters that this table does not satisfy, solutions should be given in the mufi unicode site.} can be transcribed without problem. The use of the signs is not regular and abbreviated forms are used interchangeably with the developed ones, according to the layout and the space line management. for example qui and \char"A757 , omission of macrons etc.

In general the transcription is completely graphemic, according to which a sign in the image corresponds to a sign in the transcription. Furthermore, u/v or i/j are not distinguished and transcriptions reproduce the exact manuscript spacing and signaling (space for modern spacing, : for modern commas and . between numbers and at the and of a phrase).
Orthography is by no means corrected, but philological intervention was necessary (but fortunately limited) to the letters that are inverted, almost all of the cases \footnote{There is one case of an inverted "t" in the word \textit{Cocyto} in page 4 that was correctly transcribed. Other common instances where the u was inverted are \textit{quorum}, \textit{coniuge} and \textit{genuit}. } a u inverted, giving an n, as seen in the example below:

\begin{figure}[!h]
    \centering
    \includegraphics[width=5cm]{neptunni.jpg}
    \caption{Two instances of the genitive \textit{neptunni} , one with a reversed u and one corrected.}
    \label{fig:SecFigure}
\end{figure}
In case of doubt over a given word, the transcriber verified if the form exists or not via the Collatinus lemmatiser \hyperref[Collatinus]{https://outils.biblissima.fr/fr/collatinus-web/} before the correction.

For the training of the model for the transcription the procedure was the following:
First, the 20 first pages (10 folios) were transcribed manually, and constituted the initial corpus of training. They were progressively inserted to the model 5, giving respectively 4 pages of verification. These 4 pages were then corrected manually and were reinserted to the model (fine-tuning). Lastly, another 3 pages were corrected and added to the model with the same method, which gave a very satisfying outcome and an accuracy level of 97\%.
\begin{figure}[!h]
    \centering
    \includegraphics[width=5cm]{training_status.jpg}
    \caption{The training status of the recognition and segmentation models respectively.}
    \label{fig:ThirdFigure}
\end{figure}

Automatic transcription is not magic and a certain number of recurrent errors was observed.
\begin{figure}[!h]
    \centering
    \includegraphics[width=10cm]{good_transcription.jpg}
    \caption{In some cases, the transcription is quasi perfect.}
    \label{fig:SecFigure}
\end{figure}

Namely, 
\begin{enumerate}
    \item the fist or last line of the document is almost always filled with errors, even if the ones that follow are more or less accurate;
    \item \textit{idem} with the first or last letter of every line, depending on how well the lines are designated during segmentation.
    \item double consonants or vowels are reduced to one instead of two;
    \item omission of the "i" in the particle \textit{si};
    \item open s, the letter f and the first component of the abbreviation of \textit{secundum} (\char"1E9C m) are sometimes confused;
    \item \textit{idem} for the letters b and h;
\end{enumerate}

This means that assisted post correction is needed for the most part, a statement that does not nevertheless undermine the overall efficiency of the model, as the time of transcription has been significantly reduced.


\section{BnF. Rés. J-845}
\subsection{Segmentation process,norms and limits}
\subsection{Transcription process,norms and limits}

\section{Re-framing the project and collaboration perspectives}

HTR United norms and framework. Why. How can this facilitate transcription proceedures and implementation of new texts. 

\cite{chagueclerice2021}

in the git repository : Chagué, A., Clérice, T. HTR-United, a centralization effort of HTR and OCR ground-truth repositories mainly for French languages [Computer software] :
providing a quality control test for characters.

\clearpage

\section{Prospects for collaboration}

\clearpage

\tableofcontents
%
\printbibliography
%

\end{document}
